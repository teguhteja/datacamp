# Write your own pooling operation

Write your own pooling operation
As we have seen before, CNNs can have a lot of parameters. Pooling layers are often added between the convolutional layers of a neural network to summarize their outputs in a condensed manner, and reduce the number of parameters in the next layer in the network. This can help us if we want to train the network more rapidly, or if we don't have enough data to learn a very large number of parameters.

A pooling layer can be described as a particular kind of convolution. For every window in the input it finds the maximal pixel value and passes only this pixel through. In this exercise, you will write your own max pooling operation, based on the code that you previously used to write a two-dimensional convolution operation.

Instructions
100 XP
Index into the input array (im) and select the right window.
Find the maximum in this window.
Allocate this into the right entry in the output array (result).

# Result placeholder
result = np.zeros((im.shape[0]//2, im.shape[1]//2))

# Pooling operation
for ii in range(result.shape[0]):
    for jj in range(result.shape[1]):
        result[ii, jj] = np.max(____)


Here’s how you can implement a custom max pooling operation in Python using NumPy:

```python
import numpy as np

# Assuming im is your input array (2D image) and it's of shape (height, width)
# Result placeholder
result = np.zeros((im.shape[0] // 2, im.shape[1] // 2))

# Pooling operation
for ii in range(result.shape[0]):
    for jj in range(result.shape[1]):
        # Index into the input array and select the right window (2x2)
        window = im[ii * 2: ii * 2 + 2, jj * 2: jj * 2 + 2]
        result[ii, jj] = np.max(window)

# Now, result contains the pooled output
```

### Explanation:
1. **Input Shape**: The input array `im` is assumed to be a 2D array (for example, a grayscale image).
2. **Result Placeholder**: The `result` array is initialized with zeros, with half the height and width of the input array because we are performing a 2x2 pooling operation.
3. **Pooling Operation**:
   - A nested loop iterates over the `result` dimensions.
   - For each position `(ii, jj)`, a 2x2 window is selected from the input array using slicing.
   - The maximum value in that window is found using `np.max()` and assigned to the corresponding position in the `result` array.

This operation effectively downsamples the input array by taking the maximum value from each 2x2 block of pixels.


Here’s a detailed explanation of the provided Keras model code for building a Convolutional Neural Network (CNN):

```python
# Add a convolutional layer
model.add(Conv2D(15, kernel_size=2, activation='relu', 
                 input_shape=(img_rows, img_cols, 1)))
```

### Explanation:

1. **Add a Convolutional Layer**:
   - **`model.add(Conv2D(...))`**: This line adds a convolutional layer to the model.
   - **Parameters**:
     - **`15`**: This is the number of filters (or kernels) the convolutional layer will use. Each filter will learn to recognize different features from the input images.
     - **`kernel_size=2`**: This specifies the size of the filter, which in this case is 2x2 pixels.
     - **`activation='relu'`**: The ReLU (Rectified Linear Unit) activation function is applied to introduce non-linearity to the model. It helps the network learn complex patterns by allowing positive values to pass through while setting negative values to zero.
     - **`input_shape=(img_rows, img_cols, 1)`**: This defines the shape of the input images. `img_rows` and `img_cols` represent the height and width of the images, and `1` indicates that the images are grayscale (having a single channel).

```python
# Add a pooling operation
model.add(MaxPool2D(2))
```

2. **Add a Pooling Operation**:
   - **`model.add(MaxPool2D(2))`**: This line adds a max pooling layer to the model.
   - **`MaxPool2D(2)`**: The `MaxPool2D` layer performs down-sampling on the feature maps produced by the previous convolutional layer. The argument `2` specifies the pooling size, meaning it will take the maximum value from each 2x2 window in the feature map, effectively reducing its size by half (both height and width). This helps reduce computational load and helps the network become invariant to small translations in the input.

```python
# Add another convolutional layer
model.add(Conv2D(5, kernel_size=2, activation='relu'))
```

3. **Add Another Convolutional Layer**:
   - **`model.add(Conv2D(5, kernel_size=2, activation='relu'))`**: This line adds a second convolutional layer to the model.
   - **Parameters**:
     - **`5`**: This indicates that this layer will have 5 filters.
     - **`kernel_size=2`**: Again, the size of each filter is 2x2 pixels.
     - **`activation='relu'`**: The same ReLU activation is applied to this layer as well to introduce non-linearity.

```python
# Flatten and feed to output layer
model.add(Flatten())
```

4. **Flatten Layer**:
   - **`model.add(Flatten())`**: This layer takes the 2D outputs from the previous convolutional layer and flattens them into a 1D vector. This step is necessary before connecting to the fully connected (Dense) layers, as Dense layers expect 1D input.

```python
model.add(Dense(3, activation='softmax'))
```

5. **Add the Output Layer**:
   - **`model.add(Dense(3, activation='softmax'))`**: This line adds a dense (fully connected) layer.
   - **Parameters**:
     - **`3`**: This indicates that the output layer will have 3 units, corresponding to 3 classes or categories in the classification task.
     - **`activation='softmax'`**: The softmax activation function is used here. It converts the output values into probabilities that sum to 1, making it suitable for multi-class classification. Each output represents the probability of the input belonging to each of the 3 classes.

```python
model.summary()
```

6. **Model Summary**:
   - **`model.summary()`**: This method prints a summary of the model architecture, including the number of layers, output shapes, and the total number of parameters in the model. It’s useful for verifying the model structure and ensuring that it’s set up as intended.

### Summary:
The provided code builds a simple Convolutional Neural Network with the following architecture:
- **Convolutional Layer**: Detects features using 15 filters.
- **Max Pooling Layer**: Reduces dimensionality and highlights the most important features.
- **Second Convolutional Layer**: Further extracts features using 5 filters.
- **Flatten Layer**: Prepares the 2D feature maps for input to the dense layer.
- **Dense Output Layer**: Produces probabilities for 3 categories.

This model is typically used for image classification tasks, where the input is an image, and the output is one of several predefined classes.
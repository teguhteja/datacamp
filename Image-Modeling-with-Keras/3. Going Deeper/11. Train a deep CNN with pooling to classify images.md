# Train a deep CNN with pooling to classify images

Train a deep CNN with pooling to classify images
Training a CNN with pooling layers is very similar to training of the deep networks that y have seen before. Once the network is constructed (as you did in the previous exercise), the model needs to be appropriately compiled, and then training data needs to be provided, together with the other arguments that control the fitting procedure.

The following model from the previous exercise is available in your workspace:

Convolution => Max pooling => Convolution => Flatten => Dense

Instructions
100 XP
Compile this model to use the categorical cross-entropy loss function and the Adam optimizer.
Train the model for 3 epochs with batches of size 10.
Use 20% of the data as validation data.
Evaluate the model on test_data with test_labels (also batches of size 10).

# Compile the model
____

# Fit to training data
____

# Evaluate on test data 
____


To train the deep CNN with pooling to classify images, you will need to compile the model, fit it to the training data, and then evaluate its performance on the test data. Below is the code to achieve this, following the provided instructions:

```python
# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Fit to training data
model.fit(train_data, train_labels, epochs=3, batch_size=10, validation_split=0.2)

# Evaluate on test data
test_loss, test_accuracy = model.evaluate(test_data, test_labels, batch_size=10)

print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")
```

### Explanation:

1. **Compile the Model**:
   - **`model.compile(...)`**: This method configures the model for training.
     - **`loss='categorical_crossentropy'`**: This is the loss function used for multi-class classification problems. It measures the dissimilarity between the true labels and the predicted probabilities.
     - **`optimizer='adam'`**: Adam is an adaptive learning rate optimization algorithm that combines the benefits of two other extensions of stochastic gradient descent. It's widely used for training deep learning models.
     - **`metrics=['accuracy']`**: This argument specifies that the accuracy of the model should be tracked during training and evaluation.

2. **Fit to Training Data**:
   - **`model.fit(...)`**: This method trains the model on the training data.
     - **`train_data`**: The input data for training (should be preprocessed).
     - **`train_labels`**: The corresponding labels for the training data.
     - **`epochs=3`**: The number of complete passes through the training dataset. In this case, the model will be trained for 3 epochs.
     - **`batch_size=10`**: The number of samples per gradient update. Here, the model will be trained in batches of 10 samples.
     - **`validation_split=0.2`**: This argument reserves 20% of the training data for validation, allowing you to monitor the modelâ€™s performance on unseen data during training.

3. **Evaluate on Test Data**:
   - **`model.evaluate(...)`**: This method evaluates the model on the test data.
     - **`test_data`**: The input data for testing.
     - **`test_labels`**: The corresponding labels for the test data.
     - **`batch_size=10`**: The batch size for evaluation, the same as used during training.
   - **Returns**: The method returns the test loss and test accuracy, which are printed out.

### Summary:
This code snippet successfully compiles, trains, and evaluates a deep CNN with pooling layers for image classification. You can adjust the number of epochs, batch size, and other parameters based on your dataset and model performance needs.
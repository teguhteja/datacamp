# Turning a webpage into data using BeautifulSoup: getting the hyperlinks

Turning a webpage into data using BeautifulSoup: getting the hyperlinks
In this exercise, you'll figure out how to extract the URLs of the hyperlinks from the BDFL's webpage. In the process, you'll become close friends with the soup method find_all().

Instructions
100 XP
Use the method find_all() to find all hyperlinks in soup, remembering that hyperlinks are defined by the HTML tag <a> but passed to find_all() without angle brackets; store the result in the variable a_tags.
The variable a_tags is a results set: your job now is to enumerate over it, using a for loop and to print the actual URLs of the hyperlinks; to do this, for every element link in a_tags, you want to print() link.get('href').

```py

# Import packages
import requests
from bs4 import BeautifulSoup

# Specify url
url = 'https://www.python.org/~guido/'

# Package the request, send the request and catch the response: r
r = requests.get(url)

# Extracts the response as html: html_doc
html_doc = r.text

# create a BeautifulSoup object from the HTML: soup
soup = BeautifulSoup(html_doc)

# Print the title of Guido's webpage
print(soup.title)

# Find all 'a' tags (which define hyperlinks): a_tags


# Print the URLs to the shell
for ____ in ____:
    ____

```

It looks like the exercise expects you to use the `get()` method on each hyperlink tag instead of directly accessing the `href` attribute. Using `get()` is a good practice because it will return `None` if the attribute doesn't exist, instead of raising an error.

Here's the corrected code snippet:

```python
# Import packages
import requests
from bs4 import BeautifulSoup

# Specify url
url = 'https://www.python.org/~guido/'

# Package the request, send the request and catch the response: r
r = requests.get(url)

# Extracts the response as html: html_doc
html_doc = r.text

# Create a BeautifulSoup object from the HTML: soup
soup = BeautifulSoup(html_doc, 'html.parser')

# Print the title of Guido's webpage
print(soup.title)

# Find all 'a' tags (which define hyperlinks): a_tags
a_tags = soup.find_all('a')

# Print the URLs to the shell
for link in a_tags:
    print(link.get('href'))  # Use get() to extract the 'href' attribute
```

### Key Changes:
- **Using `get()`**: The line `print(link.get('href'))` safely retrieves the `href` attribute, returning `None` if the attribute does not exist.

This should resolve any issues regarding the method of accessing the `href` attributes of the `<a>` tags. Let me know if you need further assistance!
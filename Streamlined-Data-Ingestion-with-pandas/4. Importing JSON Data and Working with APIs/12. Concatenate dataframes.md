# Concatenate dataframes

Concatenate dataframes
In this exercise, youâ€™ll practice concatenating records by creating a dataset of the 100 highest-rated cafes in New York City according to Yelp.

APIs often limit the amount of data returned, since sending large datasets can be time- and resource-intensive. The Yelp Business Search API limits the results returned in a call to 50 records. However, the offset parameter lets a user retrieve results starting after a specified number. By modifying the offset, we can get results 1-50 in one call and 51-100 in another. Then, we can append the dataframes.

pandas (as pd), requests, and json_normalize() have been imported. The 50 top-rated cafes are already in a dataframe, top_50_cafes.

Instructions
100 XP
Add an "offset" parameter to params so that the Yelp API call will get cafes 51-100.
Concatenate the results of the API call to top_50_cafes, setting ignore_index so rows will be renumbered.
Print the shape of the resulting dataframe, cafes, to confirm there are 100 records.

# Add an offset parameter to get cafes 51-100
params = {"term": "cafe", 
          "location": "NYC",
          "sort_by": "rating", 
          "limit": 50,
          ____}

result = requests.get(api_url, headers=headers, params=params)
next_50_cafes = json_normalize(result.json()["businesses"])

# Concatenate the results, setting ignore_index to renumber rows
cafes = ____

# Print shape of cafes
____


To concatenate the results of the second API call to the existing DataFrame containing the top 50 cafes and confirm that the final DataFrame contains 100 records, you can complete the code snippet as follows:

### Completed Code Snippet

```python
# Add an offset parameter to get cafes 51-100
params = {"term": "cafe", 
          "location": "NYC",
          "sort_by": "rating", 
          "limit": 50,
          "offset": 50}  # Set the offset to 50 for the second batch

result = requests.get(api_url, headers=headers, params=params)
next_50_cafes = json_normalize(result.json()["businesses"])

# Concatenate the results, setting ignore_index to renumber rows
cafes = pd.concat([top_50_cafes, next_50_cafes], ignore_index=True)

# Print shape of cafes
print(cafes.shape)
```

### Explanation of Each Part:

1. **Setting the Offset Parameter**:
   ```python
   "offset": 50
   ```
   - **Purpose**: The offset parameter allows you to specify where to start retrieving records. By setting it to 50, this call will fetch the next set of cafes, starting from the 51st record, thus allowing you to retrieve records 51-100.

2. **Making the API Call**:
   ```python
   result = requests.get(api_url, headers=headers, params=params)
   ```
   - This line sends the request to the Yelp API with the updated parameters, including the new offset.

3. **Normalizing the JSON Response**:
   ```python
   next_50_cafes = json_normalize(result.json()["businesses"])
   ```
   - This line processes the JSON response to extract and flatten the businesses data, creating a new DataFrame called `next_50_cafes` containing the next set of cafes.

4. **Concatenating the DataFrames**:
   ```python
   cafes = pd.concat([top_50_cafes, next_50_cafes], ignore_index=True)
   ```
   - **Purpose**: This line concatenates the `top_50_cafes` DataFrame with the newly created `next_50_cafes` DataFrame.
   - **ignore_index=True**: This parameter ensures that the resulting DataFrame has a new integer index, renumbering the rows sequentially from 0 to 99 (for 100 records).

5. **Printing the Shape of the Final DataFrame**:
   ```python
   print(cafes.shape)
   ```
   - This line prints the shape of the concatenated DataFrame, which should show `(100, x)` where `x` is the number of columns, confirming that the DataFrame now contains 100 records.

### Summary

This completed code snippet effectively demonstrates how to retrieve and concatenate records from the Yelp API to build a dataset of the top 100 cafes in New York City. By using the offset parameter, you can efficiently gather additional records while maintaining a clear and organized DataFrame structure for further analysis or processing.
# Skip bad data

Skip bad data
In this exercise you'll use read_csv() parameters to handle files with bad data, like records with more values than columns. By default, trying to import such files triggers a specific error, pandas.errors.ParserError.

Some lines in the Vermont tax data here are corrupted. In order to load the good lines, we need to tell pandas to skip errors. We also want pandas to warn us when it skips a line so we know the scope of data issues.

pandas has been imported as pd. The exercise code will try to read the file. If there is a pandas.errors.ParserError, the code in the except block will run.

Instructions 1/3
35 XP
1
Try to import the file vt_tax_data_2016_corrupt.csv without any keyword arguments.
try:
  # Import the CSV without any keyword arguments
  data = ____
  
  # View first 5 records
  print(data.head())
  
except pd.errors.ParserError:
    print("Your data contained rows that could not be parsed.")

To import the file `vt_tax_data_2016_corrupt.csv` without any keyword arguments and handle any parsing errors, you can use the following code:

```python
try:
    # Import the CSV without any keyword arguments
    data = pd.read_csv("vt_tax_data_2016_corrupt.csv")
    
    # View first 5 records
    print(data.head())
    
except pd.errors.ParserError:
    print("Your data contained rows that could not be parsed.")
```

### Explanation:
1. **Try-Except Block**: 
   - The `try` block attempts to read the CSV file using `pd.read_csv` without any keyword arguments. This means pandas will use its default behavior to parse the file.
   - If there are any issues with parsing the data (like irregularities in the file format, missing delimiters, or unexpected data types), pandas will raise a `ParserError`.

2. **Handling Parsing Errors**:
   - The `except pd.errors.ParserError:` block catches this specific error and prints a message indicating that the data could not be parsed.

3. **Viewing Records**:
   - If the CSV is successfully imported, `print(data.head())` will output the first five rows of the DataFrame, giving you a glimpse of the data structure.

This approach allows you to safely attempt to load potentially corrupt or improperly formatted CSV files while providing meaningful feedback if an error occurs.

Take Hint (-10 XP)
2
Import vt_tax_data_2016_corrupt.csv with the error_bad_lines parameter set to skip bad records.
try:
  # Import CSV with error_bad_lines set to skip bad records
  data = pd.read_csv("vt_tax_data_2016_corrupt.csv", 
                     ____)
  
  # View first 5 records
  print(data.head())
  
except pd.errors.ParserError:
    print("Your data contained rows that could not be parsed.")

To import `vt_tax_data_2016_corrupt.csv` while skipping bad records using the `error_bad_lines` parameter, you can use the following code:

```python
try:
    # Import CSV with error_bad_lines set to skip bad records
    data = pd.read_csv("vt_tax_data_2016_corrupt.csv", 
                       error_bad_lines=False)
    
    # View first 5 records
    print(data.head())
    
except pd.errors.ParserError:
    print("Your data contained rows that could not be parsed.")
```

### Explanation:
1. **`error_bad_lines=False`**:
   - This parameter tells pandas to skip any lines in the CSV file that cause parsing errors instead of raising an exception. This way, the import process will continue, and only the problematic rows will be ignored.

2. **Try-Except Block**:
   - The `try` block attempts to read the CSV file with the specified parameter.
   - If there are still any critical parsing issues that prevent pandas from reading the file (like an entirely malformed file), the `except` block catches the `ParserError` and provides a message indicating that there were unresolvable parsing issues.

3. **Viewing Records**:
   - If the CSV is successfully imported, `print(data.head())` will display the first five rows of the DataFrame, allowing you to examine the data that was successfully loaded.

This method is useful for dealing with datasets that may have some irregularities but still contain a lot of usable information.

3
Update the import with the warn_bad_lines parameter set to issue a warning whenever a bad record is skipped.
try:
  # Set warn_bad_lines to issue warnings about bad records
  data = pd.read_csv("vt_tax_data_2016_corrupt.csv", 
                     error_bad_lines=False, 
                     ____)
  
  # View first 5 records
  print(data.head())
  
except pd.errors.ParserError:
    print("Your data contained rows that could not be parsed.")

To import `vt_tax_data_2016_corrupt.csv` while issuing warnings for any bad records that are skipped, you can use the `warn_bad_lines` parameter. Here's how to update your code:

```python
try:
    # Set warn_bad_lines to issue warnings about bad records
    data = pd.read_csv("vt_tax_data_2016_corrupt.csv", 
                       error_bad_lines=False, 
                       warn_bad_lines=True)
  
    # View first 5 records
    print(data.head())
  
except pd.errors.ParserError:
    print("Your data contained rows that could not be parsed.")
```

### Explanation:
1. **`warn_bad_lines=True`**:
   - This parameter, when set to `True`, will cause pandas to issue a warning message to the console whenever a bad record (a record that cannot be parsed correctly) is skipped during the import process. This is helpful for diagnosing issues with the data without stopping the entire import operation.

2. **Try-Except Block**:
   - Similar to previous examples, the `try` block attempts to read the CSV file using the specified parameters.
   - If pandas encounters serious issues that prevent it from reading the file, it will raise a `ParserError`, which is handled in the `except` block.

3. **Viewing Records**:
   - If the CSV is successfully imported, `print(data.head())` will display the first five rows of the DataFrame.

This method allows you to manage potentially problematic data while still being informed about issues that arise during the import process, which can aid in further data cleaning and analysis efforts.
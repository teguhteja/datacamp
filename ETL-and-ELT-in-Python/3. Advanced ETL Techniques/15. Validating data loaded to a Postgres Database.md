# Validating data loaded to a Postgres Database

Validating data loaded to a Postgres Database
In this exercise, you'll finally get to build a data pipeline from end-to-end. This pipeline will extract school testing scores from a JSON file and transform the data to drop rows with missing scores. In addition to this, each will be ranked by the city they are located in, based on their total scores. Finally, the transformed dataset will be stored in a Postgres database.

To give you a head start, the extract() and transform() functions have been built and used as shown below. In addition to this, pandas has been imported as pd. Best of luck!

# Extract and clean the testing scores.
raw_testing_scores = extract("testing_scores.json")
cleaned_testing_scores = transform(raw_testing_scores)

1
Update the load() function to write the clean_data DataFrame to the scores_by_city table in the schools database.
If data exists in the scores_by_city table, makes sure to replace it with the updated data.

Hint
The .to_sql() method helps store DataFrames in SQL tables, using the connection object that is provided.
Try passing "replace" to the if_exists parameter to replace existing data in the scores_by_city table with the new data.

```py
def load(clean_data, con_engine):
	# Store the data in the schools database
    clean_data.to_sql(
    	name="scores_by_city",
		con=con_engine,
		if_exists="replace",  # Make sure to replace existing data
		index=True,
		index_label="school_id"
    )
```

The provided Python code defines a function called `load()` that stores a cleaned DataFrame (`clean_data`) into a SQL database using SQLAlchemy. The data is stored in a table called `scores_by_city`. Here's a breakdown of the code:

### Code Explanation:

```python
def load(clean_data, con_engine):
    # Store the data in the schools database
    clean_data.to_sql(
        name="scores_by_city",  # Name of the table where data will be stored
        con=con_engine,         # Database connection engine
        if_exists="replace",    # If the table already exists, replace the data
        index=True,             # Write the DataFrame index as a column in the table
        index_label="school_id" # Name of the column for the DataFrame index
    )
```

### Detailed Breakdown:

1. **Function Definition (`def load(clean_data, con_engine):`)**:
   - The function `load()` takes two parameters:
     - `clean_data`: The cleaned DataFrame (the data you want to store in the database).
     - `con_engine`: The connection engine created using SQLAlchemy. This engine provides the interface to the database.

2. **`clean_data.to_sql()`**:
   - This method is used to write the `clean_data` DataFrame to a table in the database. 
   - Here's what each argument in `to_sql()` does:

   - **`name="scores_by_city"`**: 
     - This specifies the name of the table where the data will be stored. In this case, it is `scores_by_city`.

   - **`con=con_engine`**: 
     - This passes the connection engine object, which is used to interact with the database.

   - **`if_exists="replace"`**: 
     - If the table `scores_by_city` already exists in the database, it will be replaced with the new data. You can also use options like `append` (to add data to the existing table) or `fail` (to raise an error if the table already exists).
   
   - **`index=True`**: 
     - This tells pandas to include the DataFrame's index as a column when writing the data to the table. By default, pandas does not include the index as a column in the database, but setting `index=True` will include it.

   - **`index_label="school_id"`**: 
     - This is the name of the column where the DataFrame's index will be stored. Instead of the default `index`, it will be labeled `school_id`. This is useful if you want a more meaningful name for the index column in the database.

### Summary:

The function `load()` takes a cleaned DataFrame (`clean_data`) and writes it to a PostgreSQL (or other SQL-based) database table called `scores_by_city`. If the table already exists, it will replace the data inside the table. The DataFrame's index is also written as a column in the table, and it is labeled as `school_id`.


2
Load the data from the cleaned_testing_scores, using the db_engine that has already been defined.
Use pandas to read data from the scores_by_city table, and print the first few rows of the DataFrame to validate that data was persisted.

To load the cleaned data from the `cleaned_testing_scores` DataFrame into the `scores_by_city` table and then query the data to validate, you can follow this structure:

### Solution:

```python
def load(clean_data, con_engine):
    # Store the cleaned data in the scores_by_city table
    clean_data.to_sql(name="scores_by_city", con=con_engine, if_exists="replace", index=True, index_label="school_id")
    
# Call the load function, passing in the cleaned DataFrame and the database connection engine
load(cleaned_testing_scores, db_engine)

# Query the data from the scores_by_city table to validate
to_validate = pd.read_sql("SELECT * FROM scores_by_city", con=db_engine)
print(to_validate.head())
```

### Explanation:

1. **`load(clean_data, con_engine)`**: 
   - The `load` function is called with `cleaned_testing_scores` as the data to be stored and `db_engine` as the connection engine to the database. This will load the data into the `scores_by_city` table.

2. **`pd.read_sql()`**: 
   - This function is used to query data from the database using SQL. 
   - The SQL query `"SELECT * FROM scores_by_city"` retrieves all rows and columns from the `scores_by_city` table.
   - `con=db_engine` specifies the connection engine to use for executing the query.

3. **`to_validate.head()`**:
   - This prints the first few rows of the `to_validate` DataFrame to confirm that the data has been loaded correctly into the database.

### Summary:
This code snippet ensures that the `cleaned_testing_scores` DataFrame is loaded into the `scores_by_city` table and then queries the table to verify that the data has been successfully persisted.
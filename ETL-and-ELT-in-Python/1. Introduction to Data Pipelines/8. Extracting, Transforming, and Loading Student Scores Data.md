# Extracting, Transforming, and Loading Student Scores Data

Extracting, Transforming, and Loading Student Scores Data
Alright, it's time to build your own ETL pipeline from scratch. In this exercise, you'll build three functions; extract(), transform(), and load(). Then, you'll use these functions to run your pipeline.

The pandas library has been imported as pd. Enjoy!

Instructions 1/4
25 XP
1
In the extract() function, use the appropriate pandas function to read a CSV into memory.
def extract(file_name):
  # Read a CSV with a path stored using file_name into memory
  return pd.____(file_name)

You can use the `read_csv` function from pandas to read a CSV file into memory. Here's how you would complete the `extract()` function:

```python
def extract(file_name):
  # Read a CSV with a path stored using file_name into memory
  return pd.read_csv(file_name)
``` 

### Explanation
- **pd.read_csv(file_name)**: This function reads the CSV file located at `file_name` and loads it into a pandas DataFrame, which allows you to easily manipulate and analyze the data.

2
Update the transform() function to filter the data_frame to only include the columns industry_name and number_of_firms.
def extract(file_name):
  return pd.read_csv(file_name)

def transform(data_frame):
  # Filter the data_frame to only incude a subset of columns
  return ____.____[:, ["industry_name", "number_of_firms"]]

To correctly filter the `data_frame` to include only the specified columns, you can use this syntax:

```python
def transform(data_frame):
  # Filter the data_frame to only include a subset of columns
  return data_frame[["industry_name", "number_of_firms"]]
```

### Explanation
- **data_frame[["industry_name", "number_of_firms"]]**: This syntax selects the columns `industry_name` and `number_of_firms` from the `data_frame` and returns a new DataFrame containing only those columns.


3
In the load() function write the data_frame to a path stored using the parameter file_name.
def extract(file_name):
  return pd.read_csv(file_name)

def transform(data_frame):
  return data_frame.loc[:, ["industry_name", "number_of_firms"]]

def load(data_frame, file_name):
  # Write the data_frame to a CSV
  data_frame.____(____)

To write the `data_frame` to a CSV file using the provided `file_name` parameter, you can use the following code:

```python
def load(data_frame, file_name):
  # Write the data_frame to a CSV
  data_frame.to_csv(file_name, index=False)
```

### Explanation
- **data_frame.to_csv(file_name, index=False)**: This writes the `data_frame` to a CSV file at the specified `file_name` location. The `index=False` parameter is used to exclude the index from the CSV file.

4
Pass the transformed_data DataFrame to the load() function, and run the ETL pipeline.
def extract(file_name):
  return pd.read_csv(file_name)

def transform(data_frame):
  return data_frame.loc[:, ["industry_name", "number_of_firms"]]

def load(data_frame, file_name):
  data_frame.to_csv(file_name)
  
extracted_data = extract(file_name="raw_industry_data.csv")
transformed_data = transform(data_frame=extracted_data)

# Pass the transformed_data DataFrame to the load() function
____(data_frame=____, file_name="number_of_firms.csv")

To pass the `transformed_data` DataFrame to the `load()` function and run the ETL pipeline, you can complete the code as follows:

```python
# Pass the transformed_data DataFrame to the load() function
load(data_frame=transformed_data, file_name="number_of_firms.csv")
```

### Explanation
- **load(data_frame=transformed_data, file_name="number_of_firms.csv")**: This calls the `load()` function, passing in the `transformed_data` DataFrame and specifying the file name `"number_of_firms.csv"` to save the data.
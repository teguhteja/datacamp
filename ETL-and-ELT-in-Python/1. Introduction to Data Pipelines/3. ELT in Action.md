# ELT in Action

ELT in Action
Feeling pretty good about running ETL processes? Well, it's time to give ELT pipelines a try. Like before, the extract(), load(), and transform() functions have been defined for you; all you'll have to worry about is running these functions. Good luck!

Instructions
100 XP
Use the appropriate ETL function to extract data from the raw_data.csv file.
Load the raw_data DataFrame into the raw_data table in a data warehouse.
Call the transform() function to transform the data in the raw_data source table.

# Extract data from the raw_data.csv file
raw_data = ____(file_name="____.csv")

# Load the extracted_data to the raw_data table
load(data_frame=____, table_name="____")

# Transform data in the raw_data table
____(
  source_table="____", 
  target_table="cleaned_data"
)

Hereâ€™s how you can run the ELT process:

```python
# Extract data from the raw_data.csv file
raw_data = extract(file_name="raw_data.csv")

# Load the extracted raw_data to the raw_data table
load(data_frame=raw_data, table_name="raw_data")

# Transform data from the raw_data table and save to the cleaned_data table
transform(
  source_table="raw_data", 
  target_table="cleaned_data"
)
```

### Explanation:
1. **Extract**: You extract the data from `raw_data.csv` and store it in `raw_data`.
2. **Load**: You then load this `raw_data` into a table named `raw_data` in your data warehouse.
3. **Transform**: Finally, you apply the `transform` function to process the data from the `raw_data` table and save the transformed results into the `cleaned_data` table.

This approach runs an ELT pipeline, where the data is first loaded into the data warehouse and then transformed.
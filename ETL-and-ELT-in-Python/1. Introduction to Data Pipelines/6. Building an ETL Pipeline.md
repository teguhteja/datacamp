# Building an ETL Pipeline

Building an ETL Pipeline
Ready to ratchet up the fun? In this exercise, you'll be responsible for building the rest of the load() function before running each step in the ETL process. The extract() and transform() functions have been defined for you. Good luck!

Instructions
100 XP
Complete the load() function by writing the transformed_data DataFrame to a .csv file, using file_name.
Use the transform() function to clean the extracted_data DataFrame.
Load transformed_data to the transformed_data.csv file using the load() function.

def load(data_frame, file_name):
  # Write cleaned_data to a CSV using file_name
  data_frame.____(____)
  print(f"Successfully loaded data to {file_name}")

extracted_data = extract(file_name="raw_data.csv")

# Transform extracted_data using transform() function
transformed_data = ____(data_frame=____)

# Load transformed_data to the file transformed_data.csv
____(data_frame=____, file_name="transformed_data.csv")


Here's how you can complete the code to build the ETL pipeline:

```python
def load(data_frame, file_name):
  # Write cleaned_data to a CSV using file_name
  data_frame.to_csv(file_name, index=False)
  print(f"Successfully loaded data to {file_name}")

# Extract data from the raw_data.csv file
extracted_data = extract(file_name="raw_data.csv")

# Transform extracted_data using transform() function
transformed_data = transform(data_frame=extracted_data)

# Load transformed_data to the file transformed_data.csv
load(data_frame=transformed_data, file_name="transformed_data.csv")
```

### Explanation:
- **data_frame.to_csv(file_name, index=False)**: Writes the transformed data to a CSV file named `transformed_data.csv`, excluding the index column.
- **transform()**: Applies data cleaning to `extracted_data`.
- **load()**: Loads the cleaned data into the specified file.
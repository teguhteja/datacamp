# Running a data pipeline end-to-end

Running a data pipeline end-to-end
It's important to monitor the performance of a pipeline when running in production. Earlier in the course, you explored tools such as exception handling and logging. In this last exercise, we'll practice running a pipeline end-to-end, while monitoring for exceptions and logging performance.

Instructions 1/3
35 XP

1
From the pipeline_utils.py file, import the extract(), transform(), and load() functions.
import logging

# Import extract, transform, and load functions from pipeline_utils
____

To import the functions from `pipeline_utils.py` and prepare for exception handling and logging, you can do the following:

```python
import logging

# Import extract, transform, and load functions from pipeline_utils
from pipeline_utils import extract, transform, load
```

### Explanation:
- **`import logging`**: This prepares the script for setting up logging to monitor the pipeline's performance.
- **Import Functions**: `from pipeline_utils import extract, transform, load` imports the necessary functions to run the pipeline end-to-end.

2
Use the extract(), transform(), and load() functions to run the tax data pipeline end-to-end, within the try-except block.

import logging
from pipeline_utils import extract, transform, load

logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)

try:
  	# Extract, transform, and load the tax data
	raw_tax_data = ____("raw_tax_data.csv")
	clean_tax_data = ____(raw_tax_data)
	___(clean_tax_data, "clean_tax_data.parquet")
    
except Exception as e:
	pass

Here's how to run the tax data pipeline within a `try-except` block:

```python
import logging
from pipeline_utils import extract, transform, load

# Configure logging
logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)

try:
    # Extract, transform, and load the tax data
    raw_tax_data = extract("raw_tax_data.csv")
    clean_tax_data = transform(raw_tax_data)
    load(clean_tax_data, "clean_tax_data.parquet")
    
except Exception as e:
    # Log the exception if one occurs
    logging.error(f"An error occurred: {e}")
```

### Explanation:
- **Try-Except Block**: This helps catch any exceptions that may occur during the pipeline execution.
- **Logging**: `logging.error()` is used to log the exception with an error level message.


3
Use the logging module to log an info-level success message if the pipeline executes as expected.
Create an error-level log if an exception occurs within the pipeline. Be sure to include the name of the exception in the log output.

import logging
from pipeline_utils import extract, transform, load

logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)

try:
	raw_tax_data = extract("raw_tax_data.csv")
	clean_tax_data = transform(raw_tax_data)
	load(clean_tax_data, "clean_tax_data.parquet")
    
	logging.____("Successfully extracted, transformed and loaded data.")  # Log a success message.
    
except Exception as e:
	____.____(f"Pipeline failed with error: {____}")  # Log failure message

Here's the complete code with logging statements added:

```python
import logging
from pipeline_utils import extract, transform, load

# Configure logging
logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)

try:
    # Extract, transform, and load the tax data
    raw_tax_data = extract("raw_tax_data.csv")
    clean_tax_data = transform(raw_tax_data)
    load(clean_tax_data, "clean_tax_data.parquet")
    
    # Log a success message
    logging.info("Successfully extracted, transformed, and loaded data.")

except Exception as e:
    # Log an error message with the exception name
    logging.error(f"Pipeline failed with error: {e}")
```

### Explanation:
- **Logging Info-Level Message**: `logging.info()` is used to log a success message if the pipeline executes successfully.
- **Logging Error-Level Message**: `logging.error()` logs an error message if an exception occurs, including the exception details (`e`).
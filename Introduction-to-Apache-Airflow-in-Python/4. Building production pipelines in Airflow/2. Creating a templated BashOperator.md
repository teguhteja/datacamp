# Creating a templated BashOperator

Creating a templated BashOperator
You've successfully created a BashOperator that cleans a given data file by executing a script called cleandata.sh. This works, but unfortunately requires the script to be run only for the current day. Some of your data sources are occasionally behind by a couple of days and need to be run manually.

You successfully modify the cleandata.sh script to take one argument - the date in YYYYMMDD format. Your testing works at the command-line, but you now need to implement this into your Airflow DAG. For now, use the term {{ ds_nodash }} in your template - you'll see exactly what this means later on.

Ide Exercise Instruction
100XP
Create a templated_command to execute the cleandata.sh script with the current execution date given by Airflow.
Modify the BashOperator to use the templated command.
There is no need of the params parameter for the clean_task task.

from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

default_args = {
  'start_date': datetime(2023, 4, 15),
}

cleandata_dag = DAG('cleandata',
                    default_args=default_args,
                    schedule_interval='@daily')

# Create a templated command to execute
# 'bash cleandata.sh datestring'


# Modify clean_task to use the templated command
clean_task = BashOperator(task_id='cleandata_task',
                          bash_command='bash cleandata.sh datestring',
                          dag=cleandata_dag)

To create a templated command for the `BashOperator` in your Airflow DAG, you can use Jinja templating to pass the execution date to your script. The `{{ ds_nodash }}` variable in Airflow provides the execution date in `YYYYMMDD` format without dashes, which is exactly what you need for your `cleandata.sh` script.

Here's how you can modify your DAG to use the templated command:

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

default_args = {
    'start_date': datetime(2023, 4, 15),
}

cleandata_dag = DAG('cleandata',
                    default_args=default_args,
                    schedule_interval='@daily')

# Create a templated command to execute 'bash cleandata.sh {{ ds_nodash }}'
templated_command = 'bash cleandata.sh {{ ds_nodash }}'

# Modify clean_task to use the templated command
clean_task = BashOperator(
    task_id='cleandata_task',
    bash_command=templated_command,
    dag=cleandata_dag
)
```

In this setup, the `bash_command` parameter of the `BashOperator` is set to a string that includes the `{{ ds_nodash }}` template variable. When the DAG runs, Airflow will replace `{{ ds_nodash }}` with the execution date in `YYYYMMDD` format, allowing your script to process data for the correct date.
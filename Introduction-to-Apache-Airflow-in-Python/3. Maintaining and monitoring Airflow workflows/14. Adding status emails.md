# Adding status emails

Adding status emails
You've worked through most of the Airflow configuration for setting up your workflows, but you realize you're not getting any notifications when DAG runs complete or fail. You'd like to setup email alerting for the success and failure cases, but you want to send it to two addresses.

Ide Exercise Instruction
100XP
Edit the execute_report_dag.py workflow.
Add the emails airflowalerts@datacamp.com and airflowadmin@datacamp.com to the appropriate key in default_args.
Set the failure email option to True.
Configure the success email to send you messages as well.

```py
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.sensors.filesystem import FileSensor
from datetime import datetime

default_args={
    '____': [____],
    '____': True,
    'email_on_success': ____
}

report_dag = DAG(
    dag_id = 'execute_report',
    schedule_interval = "0 0 * * *",
    default_args=default_args
)

precheck = FileSensor(
    task_id='check_for_datafile',
    filepath='salesdata_ready.csv',
    start_date=datetime(2023,2,20),
    mode='reschedule',
    dag=report_dag)

generate_report_task = BashOperator(
    task_id='generate_report',
    bash_command='generate_report.sh',
    start_date=datetime(2023,2,20),
    dag=report_dag
)

precheck >> generate_report_task



```

To set up the email alerting for success and failure cases in your Airflow DAG, you need to modify the `default_args` dictionary. Here's how to complete the given code:

### Steps:
1. Add the two email addresses (`airflowalerts@datacamp.com` and `airflowadmin@datacamp.com`) under the `email` key in `default_args`.
2. Set the `email_on_failure` key to `True` to send an email on task failure.
3. Set the `email_on_success` key to `True` to send an email on task success.

### Complete Code:

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.sensors.filesystem import FileSensor
from datetime import datetime

# Define the default_args dictionary with email settings
default_args = {
    'email': ['airflowalerts@datacamp.com', 'airflowadmin@datacamp.com'],  # Add email recipients
    'email_on_failure': True,  # Enable email on failure
    'email_on_success': True,  # Enable email on success
}

# Define the DAG
report_dag = DAG(
    dag_id='execute_report',
    schedule_interval="0 0 * * *",
    default_args=default_args  # Use the default_args dictionary
)

# Define the FileSensor task to check for the data file
precheck = FileSensor(
    task_id='check_for_datafile',
    filepath='salesdata_ready.csv',
    start_date=datetime(2023, 2, 20),
    mode='reschedule',  # Adjust to reschedule mode
    dag=report_dag
)

# Define the BashOperator task to generate the report
generate_report_task = BashOperator(
    task_id='generate_report',
    bash_command='generate_report.sh',
    start_date=datetime(2023, 2, 20),
    dag=report_dag
)

# Set task dependencies: precheck should run before generate_report_task
precheck >> generate_report_task
```

### Explanation of Changes:
- **`'email'`:** Contains the list of email addresses (`airflowalerts@datacamp.com` and `airflowadmin@datacamp.com`) that will receive notifications when tasks in the DAG either succeed or fail.
- **`'email_on_failure': True`:** This ensures that an email is sent when any task fails.
- **`'email_on_success': True`:** This ensures that an email is sent when any task succeeds.
- **`default_args`:** The `default_args` dictionary is used in the DAG definition, so it applies these settings to all tasks within the DAG.

### Result:
With this configuration, both `airflowalerts@datacamp.com` and `airflowadmin@datacamp.com` will receive email notifications when the tasks in the `execute_report` DAG either succeed or fail.
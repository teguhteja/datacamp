# Defining a task SLA

Defining a task SLA
After completing the SLA on the entire workflow, you realize you really only need the SLA timing on a specific task instead of the full workflow.

The appropriate Airflow libraries are imported for you.

Instructions
100 XP
Import the timedelta object.
Add a 3 hour sla to the task.

```py
# Import the timedelta object
____

test_dag = DAG('test_workflow', start_date=datetime(2024,1,20), schedule_interval=None)

# Create the task with the SLA
task1 = BashOperator(task_id='first_task',
                     ____=____,
                     bash_command='initialize_data.sh',
                     dag=test_dag)


```

To define an SLA on a specific task in your DAG, you'll need to import `timedelta`, and then specify the `sla` argument for the task that you want to set the SLA for (in this case, `task1`). Here's how you can do it:

### Step-by-step Solution:

1. **Import the `timedelta` object**: This allows you to define a time duration for the SLA.
2. **Set the `sla` for the specific task**: You will add an SLA of 3 hours to the `task1` by passing `sla=timedelta(hours=3)`.

### Corrected Code:

```python
from datetime import timedelta, datetime
from airflow.operators.bash import BashOperator
from airflow import DAG

# Define the DAG
test_dag = DAG('test_workflow', start_date=datetime(2024, 1, 20), schedule_interval=None)

# Create the task with the SLA
task1 = BashOperator(
    task_id='first_task',
    sla=timedelta(hours=3),  # Set SLA to 3 hours
    bash_command='initialize_data.sh',
    dag=test_dag
)
```

### Explanation:
- **`timedelta(hours=3)`**: This specifies that `task1` should complete within 3 hours.
- **`sla` argument**: The `sla` argument is added to the task definition to enforce the SLA.
- **`test_dag`**: This is the DAG instance to which the task is assigned.

Now, if `task1` takes longer than 3 hours to complete, Airflow will flag it as missed and potentially trigger an alert.
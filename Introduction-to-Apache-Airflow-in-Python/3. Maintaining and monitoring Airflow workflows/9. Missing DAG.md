# Missing DAG

Missing DAG
Your manager calls you before you're about to leave for the evening and wants to know why a new DAG workflow she's created isn't showing up in the system. She needs this DAG called execute_report to appear in the system so she can properly schedule it for some tests before she leaves on a trip.

Airflow is configured using the ~/airflow/airflow.cfg file.

Ide Exercise Instruction
100XP
Examine the DAG for any errors and fix those.
Determine if the DAG has loaded after fixing the errors.
If not, determine why the DAG has not loaded and fix the final issue.

```py
from airflow import DAG
#from airflow.operators.bash import BashOperator
from airflow.sensors.filesystem import FileSensor
from datetime import datetime

report_dag = DAG(
    dag_id = 'execute_report',
    schedule_interval = "0 0 * * *"
)

precheck = FileSensor(
    task_id='check_for_datafile',
    filepath='salesdata_ready.csv',
    start_date=datetime(2023,2,20),
    mode='poke',
    dag=report_dag)

generate_report_task = BashOperator(
    task_id='generate_report',
    bash_command='generate_report.sh',
    start_date=datetime(2023,2,20),
    dag=report_dag
)

precheck >> generate_report_task


```

To fix the issue and make the DAG load properly in Airflow, you need to address the following problems:

### Issues and Fixes
1. **Import Issue**: The `BashOperator` import line is commented out. This means that the `generate_report_task` cannot be created correctly, causing the DAG to fail to load.
   - **Solution**: Uncomment the import line for `BashOperator`.

### Corrected Code
Here's the updated and corrected code:

```python
from airflow import DAG
from airflow.operators.bash import BashOperator  # Uncommented this line
from airflow.sensors.filesystem import FileSensor
from datetime import datetime

report_dag = DAG(
    dag_id='execute_report',
    schedule_interval="0 0 * * *",
    start_date=datetime(2023, 2, 20)  # Added start_date to the DAG definition
)

precheck = FileSensor(
    task_id='check_for_datafile',
    filepath='salesdata_ready.csv',
    start_date=datetime(2023, 2, 20),
    mode='poke',
    dag=report_dag
)

generate_report_task = BashOperator(
    task_id='generate_report',
    bash_command='generate_report.sh',
    start_date=datetime(2023, 2, 20),
    dag=report_dag
)

precheck >> generate_report_task
```

### Steps to Check if the DAG Has Loaded
1. **Place the DAG file**: Make sure the corrected DAG file is saved in the `dags_folder`, which is `/home/repl/workspace/dags` as specified in your `airflow info`.
2. **Check the Airflow Scheduler**:
   - Ensure the Airflow scheduler is running. You can start it using the command:
     ```bash
     airflow scheduler
     ```
3. **Verify in the Airflow UI**:
   - Open the Airflow web interface and check if the DAG `execute_report` appears in the list.
4. **Debug If the DAG Still Doesn't Load**:
   - If the DAG still doesnâ€™t load, check the Airflow logs for any error messages. This can be done using:
     ```bash
     airflow dags list
     airflow dags trigger execute_report  # To test the DAG
     ```

### Additional Checks
- **Correct File Paths**: Ensure the file path `salesdata_ready.csv` exists in the location specified.
- **Check `airflow.cfg`**: Make sure the `dags_folder` in the `~/airflow/airflow.cfg` is correctly pointing to `/home/repl/workspace/dags`.

By following these steps, the DAG should appear correctly in the Airflow system, allowing your manager to proceed with scheduling tests.
# Resampling and interpolation

1. Resampling and interpolation
00:00 - 00:12
When comparing images, differences in array shape and sampling rates can pose hurdles to analysis. Resampling is one way to address this issue.

2. Resampling changes the array shape
00:12 - 00:31
Resampling is the process of slicing your data onto a different array. It's distinct from cropping in that the field of view does not change. Instead, the amount of space sampled by each pixel is increased or decreased, which in turn changes the shape of the array.

3. Downsampling
00:31 - 01:21
One useful application is "downsampling," in which information is merged across multiple pixels to reduce the image size. Here we have loaded a brain volume from the OASIS dataset. Originally, it has 256 elements along each dimension. We'll halve this grid size using SciPy's zoom() function. zoom() adjusts the number of elements along each axis by a given factor. We pass in the volume and specify a zoom of 0.5. This reduces the number of elements on each axis by half so that it is 128 by 128 by 128. Plotting the image reveals that it now has less detail than before, but it also takes up half the amount of memory.

4. Upsampling
01:21 - 01:59
It's also possible to upsample onto denser grids. But note that this does not result in a true increase in resolution. Even though you are putting more pixels into your image, you are not adding new information that wasn't there previously. One useful application of upsampling is to make sampling rates along different dimensions equal, for example, to make voxels cubic. To upsample an image, we call the zoom() function and specify a larger zoom factor. Passing in "2" will double the width of each axis.

5. Interpolation
01:59 - 02:28
Resampling actually creates a brand new image that's based on the old one. And in most cases, filling out this new image requires estimating data that wasn't originally there. This estimation process is called interpolation. For example, here we have a simple 10 point dataset. If we want to upsample it to include 100 points, we have to estimate what the values should be between each of these original points.

6. Interpolation
02:28 - 02:43
One approach is to use the nearest original value for each new point. This a zero-order interpolation, because we aren't modeling any relationship between the original values.

7. Interpolation
02:43 - 03:06
For higher-order estimation, SciPy uses B-spline interpolation, which uses a set of functions to model the space between points. The order controls how complex these functions can be: an order of 1 is linear, an order of 2 is quadratic, and so on. In the example, you can see that cubic interpolation creates a smooth curve between points.

8. Interpolation in 2D
03:06 - 03:42
Here we've created a ten by ten toy image of ascending values. If we resample it onto a 100 by 100 grid, changing the order will affect the "smoothness" of the resulting image. With an order of 0, we return essentially the original image on a new grid. At higher orders, though, we can see a smoother gradient of change along each axis. The principal trade-off with lower and higher-order interpolation is in the computational time: fifth-order interpolation for a 3D volume can take a very long time to calculate!

9. Let's practice!
03:42 - 03:50
Now it's your turn to resample some data!